{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  # For preprocessing\n",
    "import pandas as pd  # For data handling\n",
    "from time import time  # To time our operations\n",
    "from collections import defaultdict  # For word frequency\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "import multiprocessing\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import spacy  # For preprocessing\n",
    "\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/ggiam/OneDrive/Documents/Projects/Word2Vec_Project/WordNet_Extraction/definitions.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "definitions    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def cleaning(doc):\n",
    "    # Lemmatizes and removes stopwords\n",
    "    # doc needs to be a spacy Doc object\n",
    "    txt = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    # Word2Vec uses context words to learn the vector representation of a target word,\n",
    "    \n",
    "    # Removing this temporarily as dictionary definitions with two words \n",
    "    # can be helpful in this context \n",
    "    \n",
    "    # if a sentence is only one or two words long,\n",
    "    # the benefit for the training is very small\n",
    "    if len(txt) > 1:\n",
    "        return ' '.join(txt)\n",
    "    \n",
    "brief_cleaning = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in df['definitions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to clean up everything: 2.18 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "txt = [cleaning(doc) for doc in nlp.pipe(brief_cleaning, batch_size=5000, n_process=-1)]\n",
    "\n",
    "print('Time to clean up everything: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114674, 1)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = pd.DataFrame({'clean': txt})\n",
    "df_clean = df_clean.dropna().drop_duplicates()\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 17:28:48: collecting all words and their counts\n",
      "INFO - 17:28:48: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "INFO - 17:28:49: PROGRESS: at sentence #10000, processed 78695 words and 76862 word types\n",
      "INFO - 17:28:49: PROGRESS: at sentence #20000, processed 142890 words and 129930 word types\n",
      "INFO - 17:28:49: PROGRESS: at sentence #30000, processed 210435 words and 178468 word types\n",
      "INFO - 17:28:49: PROGRESS: at sentence #40000, processed 275415 words and 219402 word types\n",
      "INFO - 17:28:49: PROGRESS: at sentence #50000, processed 339744 words and 259214 word types\n",
      "INFO - 17:28:49: PROGRESS: at sentence #60000, processed 410641 words and 304371 word types\n",
      "INFO - 17:28:49: PROGRESS: at sentence #70000, processed 482503 words and 345415 word types\n",
      "INFO - 17:28:49: PROGRESS: at sentence #80000, processed 542463 words and 378538 word types\n",
      "INFO - 17:28:49: PROGRESS: at sentence #90000, processed 631686 words and 416319 word types\n",
      "INFO - 17:28:49: PROGRESS: at sentence #100000, processed 703064 words and 456593 word types\n",
      "INFO - 17:28:49: PROGRESS: at sentence #110000, processed 765268 words and 496088 word types\n",
      "INFO - 17:28:49: collected 514949 token types (unigram + bigrams) from a corpus of 795315 words and 114674 sentences\n",
      "INFO - 17:28:49: merged Phrases<514949 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000>\n",
      "INFO - 17:28:49: Phrases lifecycle event {'msg': 'built Phrases<514949 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000> in 0.88s', 'datetime': '2025-01-23T17:28:49.867430', 'gensim': '4.3.3', 'python': '3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "sent = [row.split() for row in df_clean['clean']]\n",
    "phrases = Phrases(sent, min_count=30, progress_per=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 17:28:54: exporting phrases from Phrases<514949 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000>\n",
      "INFO - 17:28:54: FrozenPhrases lifecycle event {'msg': 'exported FrozenPhrases<265 phrases, min_count=30, threshold=10.0> from Phrases<514949 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000> in 0.82s', 'datetime': '2025-01-23T17:28:54.999601', 'gensim': '4.3.3', 'python': '3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "bigram = Phraser(phrases)\n",
    "sentences = bigram[sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43042"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq = defaultdict(int)\n",
    "for sent in sentences:\n",
    "    for i in sent:\n",
    "        word_freq[i] += 1\n",
    "len(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['have',\n",
       " 'small',\n",
       " 'especially',\n",
       " 'relate',\n",
       " 'large',\n",
       " 'person',\n",
       " 'form',\n",
       " 'usually',\n",
       " 'act',\n",
       " 'manner']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(word_freq, key=word_freq.get, reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 17:29:02: Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=300, alpha=0.03>', 'datetime': '2025-01-23T17:29:02.859766', 'gensim': '4.3.3', 'python': '3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "w2v_model = Word2Vec(min_count=20,\n",
    "                     window=2,\n",
    "                     vector_size=300,\n",
    "                     sample=6e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=cores-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 17:29:04: collecting all words and their counts\n",
      "INFO - 17:29:04: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 17:29:05: PROGRESS: at sentence #10000, processed 78351 words, keeping 14753 word types\n",
      "INFO - 17:29:05: PROGRESS: at sentence #20000, processed 141766 words, keeping 22220 word types\n",
      "INFO - 17:29:05: PROGRESS: at sentence #30000, processed 207945 words, keeping 26084 word types\n",
      "INFO - 17:29:05: PROGRESS: at sentence #40000, processed 270866 words, keeping 29118 word types\n",
      "INFO - 17:29:05: PROGRESS: at sentence #50000, processed 334435 words, keeping 31093 word types\n",
      "INFO - 17:29:05: PROGRESS: at sentence #60000, processed 404139 words, keeping 33120 word types\n",
      "INFO - 17:29:05: PROGRESS: at sentence #70000, processed 473470 words, keeping 34945 word types\n",
      "INFO - 17:29:05: PROGRESS: at sentence #80000, processed 531260 words, keeping 36716 word types\n",
      "INFO - 17:29:05: PROGRESS: at sentence #90000, processed 612509 words, keeping 39292 word types\n",
      "INFO - 17:29:05: PROGRESS: at sentence #100000, processed 682532 words, keeping 41085 word types\n",
      "INFO - 17:29:05: PROGRESS: at sentence #110000, processed 744406 words, keeping 42532 word types\n",
      "INFO - 17:29:05: collected 43042 word types from a corpus of 774361 raw words and 114674 sentences\n",
      "INFO - 17:29:05: Creating a fresh vocabulary\n",
      "INFO - 17:29:05: Word2Vec lifecycle event {'msg': 'effective_min_count=20 retains 5927 unique words (13.77% of original 43042, drops 37115)', 'datetime': '2025-01-23T17:29:05.782544', 'gensim': '4.3.3', 'python': '3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'}\n",
      "INFO - 17:29:05: Word2Vec lifecycle event {'msg': 'effective_min_count=20 leaves 645322 word corpus (83.34% of original 774361, drops 129039)', 'datetime': '2025-01-23T17:29:05.782544', 'gensim': '4.3.3', 'python': '3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'}\n",
      "INFO - 17:29:05: deleting the raw counts dictionary of 43042 items\n",
      "INFO - 17:29:05: sample=6e-05 downsamples 1551 most-common words\n",
      "INFO - 17:29:05: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 405536.1505614936 word corpus (62.8%% of prior 645322)', 'datetime': '2025-01-23T17:29:05.812547', 'gensim': '4.3.3', 'python': '3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'}\n",
      "INFO - 17:29:05: estimated required memory for 5927 words and 300 dimensions: 17188300 bytes\n",
      "INFO - 17:29:05: resetting layer weights\n",
      "INFO - 17:29:05: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-01-23T17:29:05.855567', 'gensim': '4.3.3', 'python': '3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'build_vocab'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.02 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "w2v_model.build_vocab(sentences, progress_per=10000)\n",
    "\n",
    "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 17:29:08: Word2Vec lifecycle event {'msg': 'training model with 7 workers on 5927 vocabulary and 300 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2 shrink_windows=True', 'datetime': '2025-01-23T17:29:08.526618', 'gensim': '4.3.3', 'python': '3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'train'}\n",
      "INFO - 17:29:09: EPOCH 0 - PROGRESS: at 73.04% examples, 286967 words/s, in_qsize 13, out_qsize 5\n",
      "INFO - 17:29:09: EPOCH 0: training on 774361 raw words (405306 effective words) took 1.2s, 345503 effective words/s\n",
      "INFO - 17:29:10: EPOCH 1 - PROGRESS: at 48.11% examples, 186039 words/s, in_qsize 13, out_qsize 3\n",
      "INFO - 17:29:11: EPOCH 1: training on 774361 raw words (405524 effective words) took 1.4s, 296973 effective words/s\n",
      "INFO - 17:29:12: EPOCH 2 - PROGRESS: at 64.94% examples, 258534 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 17:29:12: EPOCH 2: training on 774361 raw words (404998 effective words) took 1.2s, 326195 effective words/s\n",
      "INFO - 17:29:13: EPOCH 3 - PROGRESS: at 62.31% examples, 248823 words/s, in_qsize 9, out_qsize 4\n",
      "INFO - 17:29:13: EPOCH 3: training on 774361 raw words (405232 effective words) took 1.2s, 330035 effective words/s\n",
      "INFO - 17:29:14: EPOCH 4 - PROGRESS: at 66.61% examples, 258444 words/s, in_qsize 10, out_qsize 3\n",
      "INFO - 17:29:14: EPOCH 4: training on 774361 raw words (405808 effective words) took 1.3s, 323755 effective words/s\n",
      "INFO - 17:29:16: EPOCH 5 - PROGRESS: at 66.69% examples, 217174 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 17:29:16: EPOCH 5: training on 774361 raw words (405733 effective words) took 1.5s, 275317 effective words/s\n",
      "INFO - 17:29:17: EPOCH 6 - PROGRESS: at 60.67% examples, 243631 words/s, in_qsize 13, out_qsize 1\n",
      "INFO - 17:29:17: EPOCH 6: training on 774361 raw words (405347 effective words) took 1.2s, 324583 effective words/s\n",
      "INFO - 17:29:18: EPOCH 7 - PROGRESS: at 64.97% examples, 258836 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 17:29:18: EPOCH 7: training on 774361 raw words (405604 effective words) took 1.2s, 339363 effective words/s\n",
      "INFO - 17:29:19: EPOCH 8 - PROGRESS: at 64.94% examples, 255751 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 17:29:20: EPOCH 8: training on 774361 raw words (405077 effective words) took 1.2s, 340013 effective words/s\n",
      "INFO - 17:29:21: EPOCH 9 - PROGRESS: at 60.59% examples, 244006 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 17:29:21: EPOCH 9: training on 774361 raw words (405422 effective words) took 1.3s, 317316 effective words/s\n",
      "INFO - 17:29:22: EPOCH 10 - PROGRESS: at 60.59% examples, 243210 words/s, in_qsize 11, out_qsize 4\n",
      "INFO - 17:29:22: EPOCH 10: training on 774361 raw words (405408 effective words) took 1.2s, 328261 effective words/s\n",
      "INFO - 17:29:23: EPOCH 11 - PROGRESS: at 59.36% examples, 227338 words/s, in_qsize 14, out_qsize 0\n",
      "INFO - 17:29:23: EPOCH 11: training on 774361 raw words (405951 effective words) took 1.3s, 318303 effective words/s\n",
      "INFO - 17:29:24: EPOCH 12 - PROGRESS: at 64.89% examples, 249545 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 17:29:25: EPOCH 12: training on 774361 raw words (406068 effective words) took 1.2s, 331396 effective words/s\n",
      "INFO - 17:29:26: EPOCH 13 - PROGRESS: at 89.57% examples, 359633 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 17:29:26: EPOCH 13: training on 774361 raw words (405369 effective words) took 1.0s, 388503 effective words/s\n",
      "INFO - 17:29:27: EPOCH 14 - PROGRESS: at 62.84% examples, 245567 words/s, in_qsize 12, out_qsize 3\n",
      "INFO - 17:29:27: EPOCH 14: training on 774361 raw words (405549 effective words) took 1.2s, 329102 effective words/s\n",
      "INFO - 17:29:28: EPOCH 15 - PROGRESS: at 60.16% examples, 236722 words/s, in_qsize 10, out_qsize 4\n",
      "INFO - 17:29:28: EPOCH 15: training on 774361 raw words (405266 effective words) took 1.2s, 327829 effective words/s\n",
      "INFO - 17:29:29: EPOCH 16 - PROGRESS: at 59.36% examples, 231639 words/s, in_qsize 11, out_qsize 2\n",
      "INFO - 17:29:30: EPOCH 16: training on 774361 raw words (405544 effective words) took 1.3s, 323282 effective words/s\n",
      "INFO - 17:29:31: EPOCH 17 - PROGRESS: at 58.14% examples, 230170 words/s, in_qsize 14, out_qsize 0\n",
      "INFO - 17:29:31: EPOCH 17: training on 774361 raw words (405363 effective words) took 1.3s, 314478 effective words/s\n",
      "INFO - 17:29:32: EPOCH 18 - PROGRESS: at 57.08% examples, 219641 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 17:29:32: EPOCH 18: training on 774361 raw words (405353 effective words) took 1.3s, 309309 effective words/s\n",
      "INFO - 17:29:33: EPOCH 19 - PROGRESS: at 67.68% examples, 263428 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 17:29:33: EPOCH 19: training on 774361 raw words (405628 effective words) took 1.2s, 346643 effective words/s\n",
      "INFO - 17:29:34: EPOCH 20 - PROGRESS: at 63.80% examples, 249968 words/s, in_qsize 10, out_qsize 4\n",
      "INFO - 17:29:35: EPOCH 20: training on 774361 raw words (405075 effective words) took 1.2s, 334199 effective words/s\n",
      "INFO - 17:29:36: EPOCH 21 - PROGRESS: at 73.04% examples, 271927 words/s, in_qsize 14, out_qsize 3\n",
      "INFO - 17:29:36: EPOCH 21: training on 774361 raw words (405039 effective words) took 1.2s, 343537 effective words/s\n",
      "INFO - 17:29:37: EPOCH 22 - PROGRESS: at 87.07% examples, 352201 words/s, in_qsize 10, out_qsize 0\n",
      "INFO - 17:29:37: EPOCH 22: training on 774361 raw words (405321 effective words) took 1.0s, 389711 effective words/s\n",
      "INFO - 17:29:38: EPOCH 23 - PROGRESS: at 58.14% examples, 224978 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 17:29:38: EPOCH 23: training on 774361 raw words (405458 effective words) took 1.3s, 311659 effective words/s\n",
      "INFO - 17:29:39: EPOCH 24 - PROGRESS: at 64.94% examples, 255173 words/s, in_qsize 14, out_qsize 0\n",
      "INFO - 17:29:39: EPOCH 24: training on 774361 raw words (405371 effective words) took 1.2s, 331176 effective words/s\n",
      "INFO - 17:29:40: EPOCH 25 - PROGRESS: at 68.36% examples, 260443 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 17:29:41: EPOCH 25: training on 774361 raw words (405592 effective words) took 1.2s, 340637 effective words/s\n",
      "INFO - 17:29:42: EPOCH 26 - PROGRESS: at 62.49% examples, 248342 words/s, in_qsize 12, out_qsize 5\n",
      "INFO - 17:29:42: EPOCH 26: training on 774361 raw words (405387 effective words) took 1.2s, 344010 effective words/s\n",
      "INFO - 17:29:43: EPOCH 27 - PROGRESS: at 64.94% examples, 255305 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 17:29:43: EPOCH 27: training on 774361 raw words (405688 effective words) took 1.2s, 329854 effective words/s\n",
      "INFO - 17:29:44: EPOCH 28 - PROGRESS: at 56.95% examples, 225082 words/s, in_qsize 10, out_qsize 4\n",
      "INFO - 17:29:44: EPOCH 28: training on 774361 raw words (405215 effective words) took 1.3s, 314140 effective words/s\n",
      "INFO - 17:29:45: EPOCH 29 - PROGRESS: at 64.24% examples, 251230 words/s, in_qsize 11, out_qsize 4\n",
      "INFO - 17:29:46: EPOCH 29: training on 774361 raw words (405145 effective words) took 1.2s, 341479 effective words/s\n",
      "INFO - 17:29:46: Word2Vec lifecycle event {'msg': 'training on 23230830 raw words (12162841 effective words) took 37.6s, 323766 effective words/s', 'datetime': '2025-01-23T17:29:46.094590', 'gensim': '4.3.3', 'python': '3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 0.63 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ggiam\\AppData\\Local\\Temp\\ipykernel_20912\\514372312.py:1: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  w2v_model.init_sims(replace=True)\n",
      "WARNING - 17:04:31: destructive init_sims(replace=True) deprecated & no longer required for space-efficiency\n"
     ]
    }
   ],
   "source": [
    "w2v_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('steel', 0.701933741569519),\n",
       " ('hammer', 0.662426769733429),\n",
       " ('perforate', 0.6590691804885864),\n",
       " ('iron', 0.6523343324661255),\n",
       " ('alloy', 0.6490715146064758),\n",
       " ('molten', 0.6463151574134827),\n",
       " ('tin', 0.6458144187927246),\n",
       " ('zinc', 0.6158932447433472),\n",
       " ('revolving', 0.6124913096427917),\n",
       " ('oxide', 0.596883237361908)]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"metal\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 17:30:41: vectors for words {'arian'} are not present in the model, ignoring these words\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'man'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.doesnt_match(['man', 'woman', 'arian'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07828937"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity('law', 'drink')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "w2v",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
